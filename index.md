---
layout: default
---

I am an [IFML](https://www.ifml.institute)  Postdoctoral Fellow based at [UT Austin](https://www.cs.utexas.edu) 
working with [Adam Klivans][klivans] and [Raghu Meka][meka]. I received my PhD from Computer Science Department of University of
[Wisconsin-Madison][uwm], where I was fortunate to be advised by Professor
[Christos Tzamos][tzamos-page].  Before coming to UW-Madison, I studied Electrical and Computer Engineering at
the [National Technical University of Athens][ece-ntua] where I was advised by Professor [Dimitris Fotakis][fotakis-page].

Here is a more complete [CV](assets/cv/cv.pdf).

[uwm]: https://www.wisc.edu/
[ece-ntua]: https://www.ece.ntua.gr/en
[email-me]: mailto:vkonton@gmail.com
[tzamos-page]: https://tzamos.com/
[klivans]: https://www.cs.utexas.edu/users/klivans/
[meka]: https://raghumeka.github.io
[fotakis-page]: https://www.softlab.ntua.gr/~fotakis/
[thesis-link]: http://artemis.cslab.ntua.gr/Dienst/UI/1.0/Display/artemis.ntua.ece/DT2017-0274?abstract=%EA%EF%ED%F4%EF%ED%DE%F2

## Publications

1. Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension <br/>
   w/ G. Chandrasekaran, [A. Klivans][klivans], [R. Meka][meka], K. Stavropoulos <br/>
   <b style='color:red;'> Best Paper Award </b> <br/>
   [COLT 2024](http://learningtheory.org/colt2024/)

1. Active Learning with Simple Questions <br/>
   w/ M. Ma, [C. Tzamos][tzamos] <br/>
   [COLT 2024](http://learningtheory.org/colt2024/)

1. Agnostically Learning Multi-index Models with Queries <br/>
    w/ [I. Diakonikolas][idiakonikolas], [D. Kane][kane], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/> 
    [FOCS 2024](https://focs.computer.org/2024/)

1. [Super Non-singular Decompositions of Polynomials and their](https://arxiv.org/html/2404.00529v1) <br/>
   [Application to Robustly Learning Low-degree PTFs](https://arxiv.org/html/2404.00529v1) <br/>
   w/ [I. Diakonikolas][idiakonikolas], [D M. Kane][kane], [S. Liu], [N. Zarifis][zarifis] <br/>
   [STOC 2024](http://acm-stoc.org/stoc2024/)

1. [Optimizing Solution-Samplers for Combinatorial Problems:](https://arxiv.org/pdf/2310.05309.pdf) <br/>
   [The Landscape of Policy Gradient Methods](https://arxiv.org/pdf/2310.05309.pdf) <br/>
   w/ [C. Caramanis][caramanis], [D. Fotakis][fotakis], [A. Kalavasis][kalavasis], [C. Tzamos][tzamos] <br/>
   Selected for Oral Presentation <br/>
   [NeurIPS 2023](https://nips.cc) 

1. [SLaM: Student-Label Mixing for Distillation with Unlabeled Examples](https://arxiv.org/abs/2302.03806) <br/>
    w/ [F. Iliopoulos][iliopoulos], [K. Trinh][trinh], [C. Baykal][baykal], [G. Menghani][menghani],  [V. Erik][vee] <br/> 
    [NeurIPS 2023](https://nips.cc)

1. [The Gain from Ordering in Online Learning](https://openreview.net/pdf?id=OaUT4hX40s) <br/>
   w/ M. Ma, [C. Tzamos][tzamos] <br/>
   [NeurIPS 2023](https://nips.cc) 

1. [Efficient Testable Learning of Halfspaces with Adversarial Label Noise](https://arxiv.org/abs/2303.05485) <br/>
   w/ [I. Diakonikolas][idiakonikolas], [D M. Kane][kane], [S. Liu], [N. Zarifis][zarifis] <br/>
   [NeurIPS 2023](https://nips.cc) 

1. [Self Directed Linear Classification](https://arxiv.org/abs/2308.03142) <br/> 
   w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/>
   [COLT 2023](http://learningtheory.org/colt2023/)

1. [Weighted Distillation with Unlabeled Examples](https://arxiv.org/abs/2210.06711) <br/>
    w/ [F. Iliopoulos][iliopoulos], [C. Baykal][baykal], [G. Menghani][menghani], [K. Trinh][trinh], [V. Erik][vee] <br/> 
    [NeurIPS 2022](https://nips.cc)

1.  [Linear Label Ranking with Bounded Noise](https://openreview.net/pdf?id=dgWo-UyVEsa) <br/>
    w/ [D. Fotakis][fotakis], [A. Kalavasis][kalavasis], [C. Tzamos][tzamos] <br/>
    Selected for Oral Presentation <br/>
    [NeurIPS 2022](https://nips.cc)

1. [Learning General Halfspaces with Adversarial Label Noise via Online Gradient Descent](https://proceedings.mlr.press/v162/diakonikolas22b.html) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/> 
    [ICML 2022](https://icml.cc)

1. [Learning a Single Neuron with Adversarial Label Noise via Gradient Descent](https://arxiv.org/abs/2206.08918) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/> 
    [COLT 2022](http://learningtheory.org/colt2022/)

1. [Learning General Halfspaces with General Massart Noise under the Gaussian Distribution](https://arxiv.org/abs/2108.08767) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [D. Kane][kane], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/> 
    [STOC 2022](http://acm-stoc.org/stoc2022/)

1. [A Statistical Taylor Theorem and Extrapolation of Truncated Densities](https://arxiv.org/abs/2106.15908) <br/>
    w/ [C. Daskalakis][daskalakis], [C. Tzamos][tzamos], [M. Zampetakis][zampetakis] <br/>
    [COLT 2021](http://www.learningtheory.org/colt2021/)

1. [Agnostic Proper Learning of Halfspaces under Gaussian Marginals](https://arxiv.org/abs/2102.05629) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [D. Kane][kane], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/>
    [COLT 2021](http://www.learningtheory.org/colt2021/)

1. [Efficient Algorithms for Learning from Coarse Labels](http://proceedings.mlr.press/v134/fotakis21a.html) <br/>
    w/ [D. Fotakis][fotakis], [A. Kalavasis][kalavasis], [C. Tzamos][tzamos] <br/>
    [COLT 2021](http://www.learningtheory.org/colt2021/)

1. [Learning Online Algorithms with Distributional Advice](http://proceedings.mlr.press/v139/diakonikolas21a.html) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [A. Vakilian][vakilian], [N. Zarifis][zarifis] <br/>
    [ICML 2021](https://icml.cc)

1. [A Polynomial Time Algorithm For Learning Halfspaces with Tsybakov Noise](https://arxiv.org/abs/2010.01705) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [D. Kane][kane], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/>
    [STOC 2021](http://acm-stoc.org/stoc2021/)

1. [Learning Halfspaces with Tsybakov Noise](https://arxiv.org/abs/2006.06467) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/>
    [STOC 2021](http://acm-stoc.org/stoc2021/) <br/>
    Conference version merged with the above paper

1. [Non-Convex SGD Learns Halfspaces with Adversarial Label Noise](https://arxiv.org/abs/2006.06742) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/>
    [NeurIPS 2020](http://learningtheory.org/colt2020/)

1.  [Learning Halfspaces with Massart Noise Under Structured Distributions](https://arxiv.org/abs/2002.05632)  <br/>
    w/ [I. Diakonikolas][idiakonikolas], [C. Tzamos][tzamos], [N. Zarifis][zarifis] <br/>
    [COLT 2020](http://learningtheory.org/colt2020/)

1.  [Algorithms and SQ Lower Bounds for PAC Learning One-Hidden-Layer ReLU Networks](https://arxiv.org/abs/2006.12476) <br/>
    w/ [I. Diakonikolas][idiakonikolas], [D. Kane][kane], [N. Zarifis][zarifis] <br/>
    [COLT 2020](http://learningtheory.org/colt2020/)

1.  [Efficient Truncated Statistics with Unknown Truncation](https://arxiv.org/abs/1908.01034) <br/>
    w/ [C. Tzamos][tzamos], [M. Zampetakis][zampetakis] <br/>
    [FOCS 2019](http://focs2019.cs.jhu.edu/)

1.  Removing Bias in Maching Learning via Truncated Statistics <br/>
    w/ [C. Daskalakis][daskalakis],  [C. Tzamos][tzamos], [M. Zampetakis][zampetakis] <br/>
    Manuscript

1. [Opinion Dynamics with Limited Information][OpinionDynamics] <br/>
   w/ [D. Fotakis][fotakis], V. Kandiros,  [S. Skoulakis][skoulakis] <br/>
   [WINE 2018](https://www.cs.ox.ac.uk/conferences/wine2018/)

1. [Learning Powers of Poisson Binomial Distributions][PBDpowers] <br/>
   w/ [D. Fotakis][fotakis], [P. Krysta][krysta], [P. Spirakis][spirakis] <br/>
   Manuscript


[OpinionDynamics]:https://github.com/vkonton/opinion_dynamics/blob/master/clean.pdf
[PBDpowers]:http://arxiv.org/abs/1707.05662
[zarifis]:https://nikoszarifis.github.io
[caramanis]:https://caramanis.github.io
[fotakis]:https://www.softlab.ntua.gr/~fotakis/
[krysta]:http://cgi.csc.liv.ac.uk/~piotr/
[kane]:https://cseweb.ucsd.edu/~dakane/
[spirakis]:https://intranet.csc.liv.ac.uk/news/item.php?id=19
[tzamos]:https://tzamos.com
[zampetakis]:http://www.mit.edu/~mzampet/
[daskalakis]:https://people.csail.mit.edu/costis/
[skoulakis]:http://www.corelab.ntua.gr/~sskoul/
[idiakonikolas]:http://www.iliasdiakonikolas.org/
[vakilian]:http://www.mit.edu/~vakilian/
[kalavasis]:https://alkisk.github.io
[vee]:https://scholar.google.com/citations?user=1u8drP0AAAAJ&hl=en
[trinh]:https://scholar.google.com/citations?user=pVTeodYAAAAJ&hl=en
[baykal]:https://people.csail.mit.edu/baykal/
[menghani]:http://www.gaurav.ai
[iliopoulos]:https://filiop.org
[meka]:https://hackmd.io/@raghum/index
[klivans]:https://www.cs.utexas.edu/users/klivans/


## Service
**Reviewer:** STOC, SODA, WINE, ICML, EC, MFCS, TCS, ALT


## Talks

* Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension, [IPAM 2024](https://www.youtube.com/watch?v=XJSz3XoNdlY)

* Optimizing Solution-Samplers for Combinatorial Problems, [NeurIPS 2023 Oral](https://nips.cc/virtual/2023/oral/73826)

* SLaM: Student-Label Mixing for Distillation with Unlabeled Examples, [NeurIPS 2023](https://nips.cc/virtual/2023/poster/71876)

* Learning General Halfspaces with General Massart Noise, [STOC 2022](https://www.youtube.com/watch?v=jm8K7_7HjZE)

* A Statistical Taylor's Theorem and Extrapolation of Truncated Densities, COLT 2021

* Agnostic Proper Learning of Halfspaces under Gaussian Marginals COLT 2021

* Efficient Algorithms for Learning Halfspaces with Tsybakov Noise, STOC 2021

* Non-Convex SGD Learns Halfspaces with Adversarial Label Noise, NeurIPS 2020

* Learning Halfspaces with Massart Noise Under Structured Distributions, COLT 2020

* [Efficient Truncated Statistics with Unknown Truncation][truncated_unknown],
  FOCS 2019, [Video]


* [Learning PBD Powers][pbdpowers],
   ECCO Research Seminar 2017, University of Liverpool


* Learning Theory Study Group, Corelab NTUA, 2017
   1. [Intoduction, No Free Lunch, Bias-Variance Tradeoff][learning1]
   2. [VC-Dimension][learning2]


* [Convex Optimization Minicourse][convex-minicourse], Corelab NTUA, 2017
   1. [Convex Problems, LP][convex1]
   2. [QP, SOCP][convex2]
   3. [SDP, GW MaxCut][convex3]
   4. [Vector Optimization, Duality][convex4]


* [Programming with Dependent Types][dependent], NTUA, 2015

[truncated_unknown]: assets/talks/focs2019.pdf
[video]: https://www.youtube.com/watch?v=6crXE-ANK6Y&list=PL3DbynX8gwfLXOsziSLaVmiLKKjedlvks

[pbdpowers]: assets/talks/pbdPowers.pdf

[learning1]: assets/talks/learning1.pdf
[learning2]: assets/talks/learning2.pdf

[convex-minicourse]: assets/talks/convex.pdf
[convex1]: assets/talks/convex1.pdf
[convex2]: assets/talks/convex2.pdf
[convex3]: assets/talks/convex3.pdf
[convex4]: assets/talks/convex4.pdf

[dependent]: assets/talks/dependent.pdf
